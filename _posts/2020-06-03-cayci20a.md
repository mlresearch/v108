---
title: Budget-Constrained Bandits over General Cost and Reward Distributions
abstract: We consider a budget-constrained bandit problem where each arm pull incurs
  a random cost, and yields a random reward in return. The objective is to maximize
  the total expected reward under a budget constraint on the total cost. The model
  is general in the sense that it allows correlated and potentially heavy-tailed cost-reward
  pairs that can take on negative values as required by many applications. We show
  that if moments of order $(2+\gamma)$ for some $\gamma > 0$ exist for all cost-reward
  pairs, $O(\log B)$ regret is achievable for a budget $B>0$. In order to achieve
  tight regret bounds, we propose algorithms that exploit the correlation between
  the cost and reward of each arm by extracting the common information via linear
  minimum mean-square error estimation. We prove a regret lower bound for this problem,
  and show that the proposed algorithms achieve tight problem-dependent regret bounds,
  which are optimal up to a universal constant factor in the case of jointly Gaussian
  cost and reward pairs.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cayci20a
month: 0
tex_title: Budget-Constrained Bandits over General Cost and Reward Distributions
firstpage: 4388
lastpage: 4398
page: 4388-4398
order: 4388
cycles: false
bibtex_author: Cayci, Semih and Eryilmaz, Atilla and Srikant, R
author:
- given: Semih
  family: Cayci
- given: Atilla
  family: Eryilmaz
- given: R
  family: Srikant
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/cayci20a/cayci20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/cayci20a/cayci20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
